{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1rOYTAq9hAKxN4YFhTL3N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolinalibarino/Python/blob/main/Python_exercicios_de_fun%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crie um uma função, que recebe 3 parâmetros e tenha um retorno em python.\n",
        "Ela deve\n",
        "calcular o quanto o usuário irá gastar de gasolina. Para isso o usuário deverá informar:\n",
        "- Quantos KM irá viajar\n",
        "- Quantos KM o carro consome por litro de gasolina\n",
        "- Qual o Preço da Gasolina\n",
        "Para teste de mesa: Ao Final retorne o Valor gasto. Exemplo: Irei viajar 500km, meu carro\n",
        "consome 9km por litro, a gasolina custa R$ 4,00. Irei gastar: R$ 222,22.\n",
        "# O Retorno da Função seria R$ 222,22"
      ],
      "metadata": {
        "id": "CfLXCAiKaz8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gasolina(dist, litroporkm, valor):\n",
        "  total = (dist/litroporkm) * valor\n",
        "  print(\"O valor gasto é: \", total)\n",
        "\n",
        "  return total\n"
      ],
      "metadata": {
        "id": "ZHncJ3gGa1d2"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gasolina(500, 9, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZGcT4vIdT64",
        "outputId": "5ec2b7ad-fbf8-480d-eaa2-92744e7124c3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O valor gasto é:  222.22222222222223\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222.22222222222223"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crie uma função que receba como parâmetro um texto qualquer, dentro dessa função\n",
        "deverá ter um laço de repetição que percorra cada letra do texto e retorne a quantidade de\n",
        "vogais encontradas nesse texto.\n",
        "Dentro da função deverá conter:\n",
        "Uma string assim:\n",
        "vogaisstring = aeiouAEIOU\n",
        "ou uma lista assim:\n",
        "vogaislista = ['a','e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U']\n",
        "Para ir testando o algoritmo crie primeiro uma função que vá imprimindo aos poucos e\n",
        "somando aos poucos as vogais encontradas, assim com um texto pequeno você saberá se\n",
        "está funcionando, já que essa função poderá receber textos grandes posteriormente.\n"
      ],
      "metadata": {
        "id": "Bge6tgMoeWED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def texto(escrito):\n",
        "  texto = str\n",
        "  a = escrito.count ('a')\n",
        "  b = escrito.count ('e')\n",
        "  c = escrito.count ('i')\n",
        "  d = escrito.count ('o')\n",
        "  e = escrito.count ('u')\n",
        "  f = escrito.count ('A')\n",
        "  g = escrito.count ('E')\n",
        "  h = escrito.count ('I')\n",
        "  i = escrito.count ('O')\n",
        "  j = escrito.count ('U')\n",
        "\n",
        "  total = a+b+c+d+e+f+g+h+i+j\n",
        "\n",
        "  print (\"A quantidade de vogais é: \",total)\n",
        "\n"
      ],
      "metadata": {
        "id": "TFsKn0H8eYr-"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto(\"carolina e camila\")"
      ],
      "metadata": {
        "id": "uHh7Oy4tiokl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad72a9e-e86f-47ff-b84d-75c1b2f8b0a3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A quantidade de vogais é:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sabendo disso, agora eu quero que você crie uma função em Python que receba um texto\n",
        "como Parâmetro analise quantos artigos, preposições pronomes tem em um texto qualquer.\n",
        "Traga mais de um retorno:\n",
        " Primeiro uma lista de artigos e em seguida sua quantidade\n",
        " Depois a lista de preposições e sua quantidade\n",
        " Depois a lista de Pronomes (todo os tipos) e em seguida sua quantidade."
      ],
      "metadata": {
        "id": "xlf3Pv5NrL1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ISSukwrSxF",
        "outputId": "2997f4b9-314d-4675-8d20-261bb9ee1a21"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-16 15:09:01.916597: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-16 15:09:01.916699: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-16 15:09:01.916805: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-16 15:09:01.933429: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-16 15:09:03.295207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting pt-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.6.0/pt_core_news_sm-3.6.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "CodYZpZLrkK-"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load (\"pt_core_news_sm\")\n",
        "\n",
        "texto = ''' Taylor Alison Swift (Reading, 13 de dezembro de 1989) é uma cantora, compositora, atriz, diretora e\n",
        "  roteirista norte-americana. Suas composições narrativas, muitas vezes inspirada pelas suas experiências pessoais,\n",
        "  tem recebido ampla cobertura mediática e elogios críticos. Swift mudou-se para Nashville aos 14 anos de idade para\n",
        "  se tornar uma cantora de música country, assinando um contrato de composição com a Sony/ATV Music Publishing em 2004 e\n",
        "  um contrato de gravação com a Big Machine Records em 2005 e com a Republic Records em 2019. '''\n",
        "\n",
        "doc = nlp(texto)\n",
        "\n",
        "print (\"ARTIGOS\")\n",
        "print (\"\")\n",
        "\n",
        "for token in doc:\n",
        "  if token.pos_ == \"DET\" :\n",
        "     print (f\"Artigos encontrados: {token.text}\")\n",
        "\n",
        "print (\"\")\n",
        "print (\"PREPOSIÇÕES\")\n",
        "print (\"\")\n",
        "\n",
        "for token in doc:\n",
        "  if token.pos_ == \"ADP\" :\n",
        "     print (f\"Preposições encontradas: {token.text} \")\n",
        "\n",
        "print (\"\")\n",
        "print (\"PRONOMES\")\n",
        "print (\"\")\n",
        "\n",
        "for token in doc:\n",
        "  if token.pos_ == \"PRON\" or token.pos_ == \"PRP$\" or token.pos_ == \"PRP\" :\n",
        "    print (f\"Pronomes encontrados: {token.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18MhFZwKrsr8",
        "outputId": "a14e2319-bb4e-4825-9182-f8fa4813fb03"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARTIGOS\n",
            "\n",
            "Artigos encontrados: uma\n",
            "Artigos encontrados: Suas\n",
            "Artigos encontrados: suas\n",
            "Artigos encontrados: uma\n",
            "Artigos encontrados: um\n",
            "Artigos encontrados: a\n",
            "Artigos encontrados: um\n",
            "Artigos encontrados: a\n",
            "Artigos encontrados: a\n",
            "\n",
            "PREPOSIÇÕES\n",
            "\n",
            "Preposições encontradas: de \n",
            "Preposições encontradas: de \n",
            "Preposições encontradas: muitas \n",
            "Preposições encontradas: pelas \n",
            "Preposições encontradas: para \n",
            "Preposições encontradas: aos \n",
            "Preposições encontradas: de \n",
            "Preposições encontradas: de \n",
            "Preposições encontradas: de \n",
            "Preposições encontradas: com \n",
            "Preposições encontradas: em \n",
            "Preposições encontradas: de \n",
            "Preposições encontradas: com \n",
            "Preposições encontradas: em \n",
            "Preposições encontradas: com \n",
            "Preposições encontradas: em \n",
            "\n",
            "PRONOMES\n",
            "\n",
            "Pronomes encontrados: se\n"
          ]
        }
      ]
    }
  ]
}